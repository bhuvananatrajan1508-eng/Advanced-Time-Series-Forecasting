{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuvananatrajan1508-eng/Advanced-Time-Series-Forecasting/blob/main/Advanced_time_series_forecasting%20with%20DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD4GKD2PhjQw"
      },
      "outputs": [],
      "source": [
        "# Step 1: Imports & Configuration\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi5nvUTN61Ew"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/time-series forecasting.csv\"\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(df.columns)  # always check once\n",
        "\n",
        "df['Date Time'] = pd.to_datetime(\n",
        "    df['Date Time'],\n",
        "    errors='coerce',\n",
        "    infer_datetime_format=True\n",
        ")\n",
        "\n",
        "df = df.dropna(subset=['Date Time'])\n",
        "df.set_index('Date Time', inplace=True)\n",
        "df.head()\n",
        "\n",
        "# Select multivariate features\n",
        "features = [\n",
        "    'T (degC)', 'p (mbar)', 'rh (%)', 'wv (m/s)', 'wd (deg)'\n",
        "]\n",
        "\n",
        "data = df[features]\n",
        "\n",
        "# === Data acquisition verification ===\n",
        "\n",
        "print(\"Total observations:\", len(df))\n",
        "print(\"Date range:\", df.index.min(), \"to\", df.index.max())\n",
        "print(\"Missing values:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N6MpVM1EeBay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gff_koK64IU"
      },
      "outputs": [],
      "source": [
        "# Step 3: Train–Validation Split (Time-Series Safe)\n",
        "train_size = int(len(data) * 0.7)\n",
        "val_size = int(len(data) * 0.15)\n",
        "\n",
        "train_data = data.iloc[:train_size]\n",
        "val_data = data.iloc[train_size:train_size+val_size]\n",
        "test_data = data.iloc[train_size+val_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4a604r79_Ti"
      },
      "outputs": [],
      "source": [
        "# Step 4: Scaling\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_scaled = scaler.fit_transform(train_data)\n",
        "val_scaled = scaler.transform(val_data)\n",
        "test_scaled = scaler.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL4IwDGu-Dww"
      },
      "outputs": [],
      "source": [
        "# Step 5: Sequence Dataset Builder\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=48):\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx+self.seq_len]\n",
        "        y = self.data[idx+self.seq_len, 0]  # Forecast temperature\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uytBCq1L-HPR"
      },
      "outputs": [],
      "source": [
        "# Step 6: DataLoaders\n",
        "SEQ_LEN = 48\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_ds = TimeSeriesDataset(train_scaled, SEQ_LEN)\n",
        "val_ds = TimeSeriesDataset(val_scaled, SEQ_LEN)\n",
        "test_ds = TimeSeriesDataset(test_scaled, SEQ_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-UjpJm8-LC8"
      },
      "outputs": [],
      "source": [
        "# Step 7: Baseline LSTM Model (No Attention)\n",
        "class LSTMBaseline(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjaaisEX-PL3"
      },
      "outputs": [],
      "source": [
        "# Step 8: LSTM with Temporal Attention (KEY PART)\n",
        "class AttentionLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_dim, 1)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "            self.attention(lstm_out).squeeze(-1), dim=1\n",
        "        )\n",
        "\n",
        "        context = torch.sum(lstm_out * attn_weights.unsqueeze(-1), dim=1)\n",
        "        output = self.fc(context)\n",
        "\n",
        "        return output, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KMEJeZz-Sr6"
      },
      "outputs": [],
      "source": [
        "# Step 9: Training Loop (Walk-Forward Compatible)\n",
        "def train_model(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for x, y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x)[0] if isinstance(model(x), tuple) else model(x)\n",
        "        loss = criterion(preds.squeeze(), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            output = model(x)\n",
        "            out = output[0] if isinstance(output, tuple) else output\n",
        "            preds.extend(out.squeeze().cpu().numpy())\n",
        "            targets.extend(y.cpu().numpy())\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "    mae = mean_absolute_error(targets, preds)\n",
        "    return rmse, mae"
      ],
      "metadata": {
        "id": "_pVeuG0gooYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hyperparameter Search (Grid) ===\n",
        "learning_rates = [0.001, 0.0005]\n",
        "hidden_dims = [32, 64]\n",
        "best_rmse = float(\"inf\")\n",
        "best_params = {\"lr\": None, \"hidden_dim\": None}\n",
        "best_config = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for hd in hidden_dims:\n",
        "        model = AttentionLSTM(len(features), hd)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for _ in range(3):  # short search\n",
        "            train_model(model, train_loader, optimizer, criterion)\n",
        "\n",
        "        rmse, _ = evaluate(model, val_loader)\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_params[\"lr\"] = lr\n",
        "            best_params[\"hidden_dim\"] = hd\n",
        "            best_config = (lr, hd)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_config, \"RMSE:\", best_rmse)\n",
        "print(\"Best Hyperparameters:\", best_params)\n"
      ],
      "metadata": {
        "id": "arme0lpZnSUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkUriTRz-YSk"
      },
      "outputs": [],
      "source": [
        "# Step 10: Model Training\n",
        "input_dim = len(features)\n",
        "hidden_dim = 64\n",
        "\n",
        "baseline = LSTMBaseline(input_dim, hidden_dim)\n",
        "attention_model = AttentionLSTM(input_dim, hidden_dim)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_base = torch.optim.Adam(baseline.parameters(), lr=0.001)\n",
        "optimizer_attn = torch.optim.Adam(attention_model.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    base_loss = train_model(baseline, train_loader, optimizer_base, criterion)\n",
        "    attn_loss = train_model(attention_model, train_loader, optimizer_attn, criterion)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Baseline: {base_loss:.4f} | Attention: {attn_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HogeSY6R-fix"
      },
      "outputs": [],
      "source": [
        "# Step 11: Quantitative Evaluation (Baseline vs Attention)\n",
        "\n",
        "baseline_rmse, baseline_mae = evaluate(baseline, val_loader)\n",
        "attn_rmse, attn_mae = evaluate(attention_model, val_loader)\n",
        "\n",
        "print(\"Validation Results\")\n",
        "print(f\"Baseline LSTM  -> RMSE: {baseline_rmse:.4f}, MAE: {baseline_mae:.4f}\")\n",
        "print(f\"Attention LSTM -> RMSE: {attn_rmse:.4f}, MAE: {attn_mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# FIX-3: Test Set Evaluation (CRITICAL)\n",
        "# =========================================================\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_rmse, test_mae = evaluate(attention_model, test_loader)\n",
        "base_test_rmse, base_test_mae = evaluate(baseline, test_loader)\n",
        "\n",
        "print(\"\\nTest Set Results\")\n",
        "print(f\"Baseline LSTM  → RMSE: {base_test_rmse:.4f}, MAE: {base_test_mae:.4f}\")\n",
        "print(f\"Attention LSTM → RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "rz9yiiK3rY7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ewtRjTznfqJ"
      },
      "outputs": [],
      "source": [
        "# Extract one test sample for attention analysis\n",
        "x_sample, _ = test_ds[100]\n",
        "x_sample = x_sample.unsqueeze(0)\n",
        "\n",
        "_, attention_weights = attention_model(x_sample)\n",
        "attention_np = attention_weights.squeeze().detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hotu1-aEDwxH"
      },
      "outputs": [],
      "source": [
        "# Step 12b: Attention Interpretation\n",
        "\n",
        "attn_np = attention_weights.squeeze().detach().cpu().numpy()\n",
        "\n",
        "top_k = 5\n",
        "top_indices = np.argsort(attn_np)[-top_k:][::-1]\n",
        "\n",
        "print(\"Top influential time steps:\")\n",
        "for idx in top_indices:\n",
        "    print(f\"Time step {idx} -> weight {attn_np[idx]:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_vnYgSopojW"
      },
      "outputs": [],
      "source": [
        "# Ensure model exists (safety check)\n",
        "assert 'attention_model' in globals(), \"Run Step 10 (training) before Step 13\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGA_3A0ooTKM"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Step 13: Post-hoc Explainability (Integrated Gradients)\n",
        "# =========================================================\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "\n",
        "attention_model.eval()\n",
        "\n",
        "# Select one test sample\n",
        "x_ig, _ = test_ds[100]\n",
        "x_ig = x_ig.unsqueeze(0)\n",
        "\n",
        "baseline = torch.zeros_like(x_ig)\n",
        "\n",
        "ig = IntegratedGradients(lambda x: attention_model(x)[0])\n",
        "\n",
        "attributions, delta = ig.attribute(\n",
        "    x_ig,\n",
        "    baseline,\n",
        "    return_convergence_delta=True\n",
        ")\n",
        "\n",
        "attr_np = attributions.squeeze().detach().cpu().numpy()\n",
        "\n",
        "# Feature-wise attribution\n",
        "feature_importance = np.mean(np.abs(attr_np), axis=0)\n",
        "\n",
        "ig_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Integrated_Gradient_Importance\": feature_importance\n",
        "}).sort_values(by=\"Integrated_Gradient_Importance\", ascending=False)\n",
        "\n",
        "print(\"\\nIntegrated Gradients Feature Importance:\")\n",
        "print(ig_df)\n",
        "\n",
        "ig_df.to_csv(\"integrated_gradients_feature_importance.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0vGil_CEqfv"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert attention weights to numpy (already detached)\n",
        "attn = attention_np.reshape(1, -1)  # shape: (1, time_steps)\n",
        "\n",
        "plt.figure(figsize=(12, 2))\n",
        "sns.heatmap(\n",
        "    attn,\n",
        "    cmap=\"viridis\",\n",
        "    cbar=True,\n",
        "    xticklabels=10,\n",
        "    yticklabels=False\n",
        ")\n",
        "plt.title(\"Attention Heatmap Across Historical Time Steps\")\n",
        "plt.xlabel(\"Time Steps (Past → Present)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS2dpRgDEs-d"
      },
      "outputs": [],
      "source": [
        "# Assuming first feature is temperature\n",
        "temperature_series = x_sample.squeeze()[..., 0].detach().cpu().numpy()\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 4))\n",
        "\n",
        "# Temperature\n",
        "ax1.plot(temperature_series, label=\"Temperature\", color=\"tab:blue\")\n",
        "ax1.set_ylabel(\"Temperature (degC)\", color=\"tab:blue\")\n",
        "\n",
        "# Attention\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(attention_np, label=\"Attention Weight\", color=\"tab:red\", alpha=0.6)\n",
        "ax2.set_ylabel(\"Attention Importance\", color=\"tab:red\")\n",
        "\n",
        "plt.title(\"Temperature vs Attention Weights\")\n",
        "plt.xlabel(\"Historical Time Steps\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyU6723cEwiW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "top_k = 5\n",
        "top_indices = np.argsort(attention_np)[-top_k:][::-1]\n",
        "\n",
        "print(\"Top Important Time Steps (0 = oldest):\")\n",
        "for idx in top_indices:\n",
        "    print(f\"Time step {idx} → Attention = {attention_np[idx]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAG3ObdlE7bF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(attention_np)\n",
        "plt.title(\"Temporal Attention Weights\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.savefig(\"attention_weights_plot.png\", dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YpFE6NwUxfO"
      },
      "outputs": [],
      "source": [
        "# Step 14: Prediction vs Ground Truth Visualization\n",
        "\n",
        "def get_predictions(model, dataset, n=300):\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n):\n",
        "            x, y = dataset[i]\n",
        "            out = model(x.unsqueeze(0))[0] if isinstance(model(x.unsqueeze(0)), tuple) else model(x.unsqueeze(0))\n",
        "            preds.append(out.item())\n",
        "            targets.append(y.item())\n",
        "\n",
        "    return preds, targets\n",
        "\n",
        "\n",
        "# Attention model predictions\n",
        "preds, targets = get_predictions(attention_model, test_ds)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(targets, label=\"Ground Truth\", alpha=0.8)\n",
        "plt.plot(preds, label=\"Attention LSTM Prediction\", alpha=0.8)\n",
        "plt.title(\"Test Set: Prediction vs Ground Truth (Temperature)\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Temperature (scaled)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZrsPGc7OZp4P2ACTByekw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}